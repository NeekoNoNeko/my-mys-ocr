{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CRNN OCR 训练（Scheme B，自包含 Notebook 版，Windows/Notebook 适配）\n",
    "\n",
    "本 Notebook 实现了无需直接运行 code/train.py 的完整训练流程：\n",
    "- 使用 Windows/Notebook 友好设置（DataLoader num_workers=0；无 multiprocessing_context='fork'）。\n",
    "- 日志目录 runs/，检查点目录 checkpoints/。\n",
    "- 支持断点续训、早停、最佳模型保存。\n",
    "- 可选的数据集字符覆盖检查。\n",
    "- 可选推理示例。\n",
    "\n",
    "请确保：\n",
    "- 你已经准备好了 data/train.lmdb 和可选的 data/val.lmdb。\n",
    "- models/model.py 与 dataset.py 可被导入（本仓库已有）。\n",
    "- requirements.txt 已安装依赖。\n"
   ],
   "id": "3708c90263dbe48a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:57:36.568525Z",
     "start_time": "2025-08-20T09:57:36.560516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 可选：安装依赖（如已安装可跳过）\n",
    "# 在某些环境下，建议手工在终端执行：pip install -r requirements.txt\n",
    "# !pip -q install -r requirements.txt\n",
    "import sys, os\n",
    "print('Python:', sys.version)\n",
    "print('CWD:', os.getcwd())\n"
   ],
   "id": "72fb27f651203bf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]\n",
      "CWD: C:\\workspace\\mys-ocr\\notebooks\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:57:36.633912Z",
     "start_time": "2025-08-20T09:57:36.618496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports 与字符集、工具函数\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 字符集设置（与 code/train.py 保持一致，必要时按你的数据修改）\n",
    "BLANK = '-'\n",
    "CHARS = BLANK + \"OP12/403ADC@E\"\n",
    "\n",
    "# 重复字符检查\n",
    "if len(set(CHARS)) != len(CHARS):\n",
    "    duplicates = set([c for c in CHARS if CHARS.count(c) > 1])\n",
    "    raise ValueError(f'字符集 CHARS 存在重复字符: {sorted(duplicates)}，请检查并去重！')\n",
    "\n",
    "nclass = len(CHARS)\n",
    "char2idx = {c: i for i, c in enumerate(CHARS)}\n",
    "idx2char = {i: c for i, c in enumerate(CHARS)}\n",
    "\n",
    "def text_to_indices(text):\n",
    "    return [char2idx[c] for c in text if c in char2idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    label_indices = [torch.tensor(text_to_indices(label), dtype=torch.long) for label in labels]\n",
    "    label_lengths = torch.tensor([len(l) for l in label_indices], dtype=torch.long)\n",
    "    labels_concat = torch.cat(label_indices)\n",
    "    return images, labels_concat, label_lengths\n",
    "\n",
    "@torch.no_grad()\n",
    "def decode(preds):\n",
    "    # preds: (T, N, C) logit 或 log_softmax 输出\n",
    "    preds = preds.argmax(2)\n",
    "    preds = preds.permute(1, 0)  # (batch, seq)\n",
    "    texts = []\n",
    "    for pred in preds:\n",
    "        char_list = []\n",
    "        prev_idx = 0\n",
    "        for idx in pred:\n",
    "            idx = idx.item()\n",
    "            if idx != 0 and idx != prev_idx:\n",
    "                char_list.append(idx2char[idx])\n",
    "            prev_idx = idx\n",
    "        texts.append(''.join(char_list))\n",
    "    return texts\n"
   ],
   "id": "105a819e639f843c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:57:36.685707Z",
     "start_time": "2025-08-20T09:57:36.675692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入模型与数据集（复用仓库实现）\n",
    "import sys, os\n",
    "repo_root = os.path.dirname(os.getcwd()) if os.path.basename(os.getcwd()).lower() == 'notebooks' else os.getcwd()\n",
    "code_dir = os.path.join(repo_root, 'code')\n",
    "if code_dir not in sys.path:\n",
    "    sys.path.append(code_dir)\n",
    "\n",
    "# 兼容多种项目结构的导入尝试\n",
    "try:\n",
    "    from model import CRNN          # 优先 code/model.py\n",
    "    from dataset import OCRDataset  # 优先 code/dataset.py\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        from models.model import CRNN   # 备选：models/model.py\n",
    "        from dataset import OCRDataset\n",
    "    except ModuleNotFoundError:\n",
    "        # 最后尝试：从仓库根路径直接导入（若用户将文件放到了根路径）\n",
    "        if repo_root not in sys.path:\n",
    "            sys.path.append(repo_root)\n",
    "        from model import CRNN\n",
    "        from dataset import OCRDataset\n",
    "print('已导入 CRNN 与 OCRDataset')\n"
   ],
   "id": "430513c523a1cdcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已导入 CRNN 与 OCRDataset\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T09:57:36.817693Z",
     "start_time": "2025-08-20T09:57:36.737573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练配置（Windows/Notebook 友好）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# 模型超参数\n",
    "imgH = 32\n",
    "nh = 256\n",
    "nc = 1\n",
    "\n",
    "# 训练超参数（可按需调整）\n",
    "finetune = False\n",
    "pretrained_model = None  # 示例: os.path.join(repo_root, 'checkpoints', 'crnn_best.pth')\n",
    "batch_size = 64\n",
    "n_epoch = 50\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-4\n",
    "scheduler_step = 30\n",
    "scheduler_gamma = 0.7\n",
    "patience = 10\n",
    "\n",
    "# 数据路径（LMDB）\n",
    "train_lmdb = os.path.join(repo_root, 'data', 'train.lmdb')\n",
    "val_lmdb = os.path.join(repo_root, 'data', 'val.lmdb')\n",
    "use_val = os.path.isdir(val_lmdb) and any(os.scandir(val_lmdb)) if os.path.exists(val_lmdb) else False\n",
    "\n",
    "# 日志与检查点目录\n",
    "log_dir = os.path.join(repo_root, 'runs')\n",
    "ckpt_dir = os.path.join(repo_root, 'checkpoints')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((imgH, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 数据集与 DataLoader（Windows: num_workers=0）\n",
    "train_dataset = OCRDataset(lmdb_path=train_lmdb, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          collate_fn=collate_fn, num_workers=0,\n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "\n",
    "val_loader = None\n",
    "if use_val:\n",
    "    val_dataset = OCRDataset(lmdb_path=val_lmdb, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            collate_fn=collate_fn, num_workers=0,\n",
    "                            pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# 模型\n",
    "model = CRNN(imgH, nc, nclass, nh).to(device)\n",
    "\n",
    "# 微调：加载预训练\n",
    "if finetune and pretrained_model and os.path.exists(pretrained_model):\n",
    "    ckpt = torch.load(pretrained_model, map_location=device)\n",
    "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt)\n",
    "    print('Loaded pretrained weights from', pretrained_model)\n",
    "\n",
    "criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()) if finetune else model.parameters(),\n",
    "                       lr=lr, weight_decay=weight_decay, betas=(0.9, 0.95) if finetune else (0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print('Dataloaders ready. Model initialized.')\n"
   ],
   "id": "92b5f01d4a386b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "C:\\workspace\\mys-ocr\\data\\train.lmdb: ϵͳ�Ҳ���ָ����·����\r\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mError\u001B[39m                                     Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 40\u001B[39m\n\u001B[32m     33\u001B[39m transform = transforms.Compose([\n\u001B[32m     34\u001B[39m     transforms.Resize((imgH, \u001B[32m100\u001B[39m)),\n\u001B[32m     35\u001B[39m     transforms.ToTensor(),\n\u001B[32m     36\u001B[39m     transforms.Normalize((\u001B[32m0.5\u001B[39m,), (\u001B[32m0.5\u001B[39m,))\n\u001B[32m     37\u001B[39m ])\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# 数据集与 DataLoader（Windows: num_workers=0）\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m train_dataset = OCRDataset(lmdb_path=train_lmdb, transform=transform)\n\u001B[32m     41\u001B[39m train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m     42\u001B[39m                           collate_fn=collate_fn, num_workers=\u001B[32m0\u001B[39m,\n\u001B[32m     43\u001B[39m                           pin_memory=torch.cuda.is_available())\n\u001B[32m     45\u001B[39m val_loader = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\workspace\\mys-ocr\\code\\dataset.py:37\u001B[39m, in \u001B[36mOCRDataset.__init__\u001B[39m\u001B[34m(self, lmdb_path, transform, augment)\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28mself\u001B[39m._env = \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# 先不打开，惰性初始化\u001B[39;00m\n\u001B[32m     36\u001B[39m \u001B[38;5;66;03m# 只在主进程做一次统计\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m lmdb.open(lmdb_path, readonly=\u001B[38;5;28;01mTrue\u001B[39;00m, lock=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m tmp_env:\n\u001B[32m     38\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m tmp_env.begin(write=\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m txn:\n\u001B[32m     39\u001B[39m         \u001B[38;5;28mself\u001B[39m.n_samples = \u001B[38;5;28mint\u001B[39m(txn.get(\u001B[33m'\u001B[39m\u001B[33mnum-samples\u001B[39m\u001B[33m'\u001B[39m.encode()))\n",
      "\u001B[31mError\u001B[39m: C:\\workspace\\mys-ocr\\data\\train.lmdb: ϵͳ�Ҳ���ָ����·����\r\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 可选：数据集字符覆盖检查\n",
    "@torch.no_grad()\n",
    "def check_dataset_chars(dataset, char2idx):\n",
    "    dataset_chars = set()\n",
    "    print('正在检查数据集字符...')\n",
    "    for i in range(len(dataset)):\n",
    "        if i % 1000 == 0:\n",
    "            print(f'已检查 {i}/{len(dataset)} 个样本')\n",
    "        _, label = dataset[i]\n",
    "        for char in label:\n",
    "            dataset_chars.add(char)\n",
    "    missing_chars = dataset_chars - set(char2idx.keys())\n",
    "    extra_chars = set(char2idx.keys()) - dataset_chars - {BLANK}\n",
    "    if missing_chars:\n",
    "        print('数据集中存在字符集未包含的字符：', sorted(missing_chars))\n",
    "        raise ValueError('请修改 CHARS 以覆盖全部数据字符')\n",
    "    if extra_chars:\n",
    "        print('提示：字符集中存在数据集中未出现的字符：', sorted(extra_chars))\n",
    "    print(f'数据集字符检查完成，共发现 {len(dataset_chars)} 个字符')\n",
    "    return True\n",
    "\n",
    "# 按需启用：\n",
    "# check_dataset_chars(train_dataset, char2idx)\n",
    "# if val_loader is not None:\n",
    "#     check_dataset_chars(val_dataset, char2idx)\n"
   ],
   "id": "b1063b0fd562aeba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 训练循环（无交互 input，含早停与checkpoint）\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "early_stop_counter = 0\n",
    "start_epoch = 0\n",
    "resume_from = None  # 可填写 checkpoint 路径以断点续训\n",
    "\n",
    "# 断点恢复（可选）\n",
    "if resume_from and os.path.exists(resume_from):\n",
    "    print('Resuming from', resume_from)\n",
    "    checkpoint = torch.load(resume_from, map_location=device)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        best_epoch = checkpoint.get('best_epoch', 0)\n",
    "        early_stop_counter = checkpoint.get('early_stop_counter', 0)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "        m = re.search(r'epoch(\\d+)', os.path.basename(resume_from))\n",
    "        start_epoch = int(m.group(1)) if m else 0\n",
    "\n",
    "for epoch in range(start_epoch, n_epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, labels, label_lengths in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "\n",
    "        preds = model(images)                                # (T, N, C)\n",
    "        preds_log_softmax = nn.functional.log_softmax(preds, 2)\n",
    "        input_lengths = torch.full((images.size(0),), preds.size(0), dtype=torch.long, device=device)\n",
    "        ctc_loss = criterion(preds_log_softmax, labels, input_lengths, label_lengths)\n",
    "\n",
    "        # 轻度长度惩罚（可选）\n",
    "        pred_texts_for_penalty = decode(preds_log_softmax)\n",
    "        pred_lengths = torch.tensor([len(p) for p in pred_texts_for_penalty], dtype=torch.float32, device=device)\n",
    "        target_length = 21.0\n",
    "        length_penalty = nn.functional.mse_loss(pred_lengths, torch.full_like(pred_lengths, target_length))\n",
    "        loss = ctc_loss + 0.1 * length_penalty\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += ctc_loss.item()\n",
    "\n",
    "        # 训练准确率（严格字符串完全匹配）\n",
    "        pred_texts = decode(preds_log_softmax)\n",
    "        batch_size_eff = images.size(0)\n",
    "        labels_cpu = labels.detach().cpu().numpy()\n",
    "        label_lengths_cpu = label_lengths.detach().cpu().numpy()\n",
    "        gt_texts = []\n",
    "        start = 0\n",
    "        for l in label_lengths_cpu:\n",
    "            gt_texts.append(''.join([idx2char[i] for i in labels_cpu[start:start+l]]))\n",
    "            start += l\n",
    "        for p, g in zip(pred_texts, gt_texts):\n",
    "            if p == g:\n",
    "                total_correct += 1\n",
    "        total_samples += batch_size_eff\n",
    "\n",
    "    avg_train_loss = total_loss / max(1, len(train_loader))\n",
    "    train_acc = total_correct / max(1, total_samples)\n",
    "\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch + 1)\n",
    "    writer.add_scalar('Acc/train', train_acc, epoch + 1)\n",
    "    print(f'Epoch {epoch+1}/{n_epoch}, Loss: {avg_train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "\n",
    "    # 验证\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_samples = 0\n",
    "            for images, labels, label_lengths in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                label_lengths = label_lengths.to(device)\n",
    "                preds = model(images)\n",
    "                preds_log_softmax = nn.functional.log_softmax(preds, 2)\n",
    "                input_lengths = torch.full((images.size(0),), preds.size(0), dtype=torch.long, device=device)\n",
    "                loss = criterion(preds_log_softmax, labels, input_lengths, label_lengths)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                pred_texts = decode(preds_log_softmax)\n",
    "                batch_size_eff = images.size(0)\n",
    "                labels_cpu = labels.detach().cpu().numpy()\n",
    "                label_lengths_cpu = label_lengths.detach().cpu().numpy()\n",
    "                gt_texts = []\n",
    "                start = 0\n",
    "                for l in label_lengths_cpu:\n",
    "                    gt_texts.append(''.join([idx2char[i] for i in labels_cpu[start:start+l]]))\n",
    "                    start += l\n",
    "                for p, g in zip(pred_texts, gt_texts):\n",
    "                    if p == g:\n",
    "                        val_correct += 1\n",
    "                val_samples += batch_size_eff\n",
    "\n",
    "            avg_val_loss = val_loss / max(1, len(val_loader))\n",
    "            val_acc = val_correct / max(1, val_samples)\n",
    "            writer.add_scalar('Loss/val', avg_val_loss, epoch + 1)\n",
    "            writer.add_scalar('Acc/val', val_acc, epoch + 1)\n",
    "            print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    else:\n",
    "        avg_val_loss = avg_train_loss\n",
    "        val_acc = train_acc\n",
    "\n",
    "    # 调度与日志\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Learning_Rate', current_lr, epoch + 1)\n",
    "    print(f'Learning Rate: {current_lr:.6f}')\n",
    "\n",
    "    # 早停与保存\n",
    "    improved = (avg_val_loss < best_val_loss)\n",
    "    if improved:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), os.path.join(ckpt_dir, 'crnn_best.pth'))\n",
    "        print(f'保存最佳模型 (Epoch {best_epoch}, Loss: {best_val_loss:.4f})')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f'验证损失未改善，早停计数器: {early_stop_counter}/{patience}')\n",
    "\n",
    "    # 保存完整 checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_epoch': best_epoch,\n",
    "        'early_stop_counter': early_stop_counter,\n",
    "        'loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'finetune': finetune\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(ckpt_dir, f'crnn_epoch{epoch+1}.pth'))\n",
    "\n",
    "    # 早停\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f'早停触发！最佳模型在 Epoch {best_epoch}, Loss: {best_val_loss:.4f}')\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "print(f'训练完成！最佳模型在 Epoch {best_epoch}, Loss: {best_val_loss:.4f}')\n"
   ],
   "id": "bbc054d6de0fe430"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 推理/可视化示例（可选）\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "best_pth = os.path.join(ckpt_dir, 'crnn_best.pth')\n",
    "if os.path.exists(best_pth):\n",
    "    model.load_state_dict(torch.load(best_pth, map_location=device))\n",
    "    model.eval()\n",
    "    print('最佳权重已加载:', best_pth)\n",
    "else:\n",
    "    print('未找到最佳权重文件:', best_pth)\n",
    "\n",
    "# 示例：读取单张测试图并解码（请替换路径）\n",
    "# img_path = r'C:\\\\path\\\\to\\\\your\\\\test.jpg'\n",
    "# if os.path.exists(img_path):\n",
    "#     img = Image.open(img_path).convert('L')\n",
    "#     img = img.resize((100, imgH))\n",
    "#     img = transforms.ToTensor()(img)\n",
    "#     img = transforms.Normalize((0.5,), (0.5,))(img)\n",
    "#     img = img.unsqueeze(0).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(img)\n",
    "#         preds_log_softmax = nn.functional.log_softmax(preds, 2)\n",
    "#     texts = decode(preds_log_softmax)\n",
    "#     print('识别结果:', texts)\n",
    "# else:\n",
    "#     print('请设置有效的测试图像路径以运行推理示例')\n"
   ],
   "id": "dc63a09298b4124e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
